{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chunck forward.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meiF_0lcN6rU",
        "outputId": "32739eb7-e453-4a6e-eadb-3656a8edbe4d"
      },
      "source": [
        "#@title Installs and Imports\n",
        "# pip installs\n",
        "!pip -qq install git+https://github.com/huggingface/transformers.git\n",
        "!pip install -qq py3nvml\n",
        "\n",
        "from transformers import ReformerConfig, PyTorchBenchmark, PyTorchBenchmarkArguments"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8X1t8DQXIy",
        "outputId": "c9216f6e-81d1-4475-e829-be51d0b6c002"
      },
      "source": [
        "config_no_chunk = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", chunk_size_feed_forward=0, num_attention_heads=2, feed_forward_size=16384)  # no chuck\n",
        "config_chunk = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", chunk_size_feed_forward=8, num_attention_heads=2, feed_forward_size=16384)  # feed forward chunk\n",
        "benchmark_args = PyTorchBenchmarkArguments(sequence_lengths=[1024, 2048, 4096, 8192], batch_sizes=[8], models=[\"Reformer-No-Chunk\", \"Reformer-Chunk\"])\n",
        "benchmark = PyTorchBenchmark(configs=[config_no_chunk, config_chunk], args=benchmark_args)\n",
        "result = benchmark.run()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 2\n",
            "Doesn't fit on GPU. CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 15.78 GiB total capacity; 8.05 GiB already allocated; 3.17 GiB free; 11.32 GiB reserved in total by PyTorch)\n",
            "Doesn't fit on GPU. CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 15.78 GiB total capacity; 8.05 GiB already allocated; 3.17 GiB free; 11.32 GiB reserved in total by PyTorch)\n",
            "2 / 2\n",
            "\n",
            "====================       INFERENCE - SPEED - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length     Time in s   \n",
            "--------------------------------------------------------------------------------\n",
            "      Reformer-No-Chunk              8              1024           0.531     \n",
            "      Reformer-No-Chunk              8              2048           1.065     \n",
            "      Reformer-No-Chunk              8              4096           2.134     \n",
            "      Reformer-No-Chunk              8              8192            N/A      \n",
            "        Reformer-Chunk               8              1024           0.721     \n",
            "        Reformer-Chunk               8              2048           1.447     \n",
            "        Reformer-Chunk               8              4096           2.883     \n",
            "        Reformer-Chunk               8              8192           5.789     \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====================      INFERENCE - MEMORY - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length    Memory in MB \n",
            "--------------------------------------------------------------------------------\n",
            "      Reformer-No-Chunk              8              1024            4747     \n",
            "      Reformer-No-Chunk              8              2048            6603     \n",
            "      Reformer-No-Chunk              8              4096           10293     \n",
            "      Reformer-No-Chunk              8              8192            N/A      \n",
            "        Reformer-Chunk               8              1024            4263     \n",
            "        Reformer-Chunk               8              2048            5637     \n",
            "        Reformer-Chunk               8              4096            8371     \n",
            "        Reformer-Chunk               8              8192           13811     \n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}